{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1dbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types\n",
    "from pyspark import SparkConf\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a83c6ce",
   "metadata": {},
   "source": [
    "Setting appropriate jar files and mongo connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_conn = '<MONGDB_CONNECTION_STRING>'\n",
    "conf = SparkConf()\n",
    "conf.set('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1,org.mongodb.spark:mongo-spark-connector:10.0.4,com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.1' )\n",
    "conf.set(\"spark.mongodb.input.uri\", mongodb_conn)\n",
    "conf.set(\"spark.mongodb.output.uri\", mongodb_conn)\n",
    "conf.set(\"spark.driver.memory\",\"8G\")\n",
    "spark = SparkSession.builder.appName('twitter') \\\n",
    "    .master('local[*]') \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bda17",
   "metadata": {},
   "source": [
    "Reading tweets from Kafka server by subscribing to the producer topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = spark.readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', 'localhost:9092') \\\n",
    "    .option('subscribe', 'politics') \\\n",
    "    .option('startOffsets', 'earliest') \\\n",
    "    .option('failOnDataLoss', 'false') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f394e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hugging Face Model\n",
    "MODEL_NAME = 'j-hartmann/emotion-english-distilroberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed34e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceClassifier_loaded = RoBertaForSequenceClassification.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n",
    "  .setInputCols([\"document\",'token'])\\\n",
    "  .setOutputCol(\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba2634",
   "metadata": {},
   "source": [
    "Each row in the source has the following schema\n",
    "\n",
    "- key - binary\n",
    "- value - binary\n",
    "- topic - string\n",
    "- partition - int\n",
    "- offset - long\n",
    "- timestamp - long\n",
    "- timestampType - int\n",
    "\n",
    "To read the data (value) from binary it needs to be converted to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweets.selectExpr(\"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df.withColumnRenamed('value', 'text').withColumnRenamed('timestamp', 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document') \\\n",
    "    .setCleanupMode('shrink')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    tokenizer,\n",
    "    sequenceClassifier_loaded    \n",
    "])\n",
    "\n",
    "result = pipeline.fit(tweet_df).transform(tweet_df)\n",
    "result = result.select(\"text\", 'time', \"class.result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b66e1",
   "metadata": {},
   "source": [
    "Writing the tweets with emotion classified to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = result.writeStream \\\n",
    "    .format(\"mongodb\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option('spark.mongodb.connection.uri', mongodb_conn) \\\n",
    "    .option(\"spark.mongodb.database\", \"MONGODB_DATABASE\") \\\n",
    "    .option(\"spark.mongodb.collection\", \"<MONGODB_COLLECTION>\") \\\n",
    "    .option('checkpointLocation', '<PATH_FOR_CHECKPOINT_LOCATION>') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
